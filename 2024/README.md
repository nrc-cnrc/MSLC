# MSLC24 Data

## Overview
This directory contains data and additional figures associated with the paper [_MSLC24: Further Challenges for Metrics on a Wide Landscape of Translation Quality_](https://aclanthology.org/2024.wmt-1.34/) by Rebecca Knowles, Samuel Larkin, and Chi-kiu Lo, published at WMT 2024.

Additional figures and data to be added shortly.

## Data
Within the `data/` directory, you will find two subdirectories, covering the two halves of the 2024 MSLC dataset: `MSLC-A/` and `MSLC-B/`. While the General MT task uses three-letter language codes, we use the two-letter codes here for consistency with the Metrics task. These are as follows: English (eng, en), German (deu, de), Spanish (spa, es), Japanese (jpn, ja), and Chinese (zho, zh).

The `MSLC-A` data focuses on the range of MT quality (low- to mid-level quality), while the `MLSC-B` data targets more specific phenomena.

### MSLC-A
Within the `MSLC-A/` directory you will find subdirectories that are designed to be similar to the ones used by MTME ([https://github.com/google-research/mt-metrics-eval#specification](https://github.com/google-research/mt-metrics-eval#specification)). They contain the MT output from the systems in the `MSLC24-A` challenge set as well as the scores assigned to those by the participating metrics. All language pairs use `refA` as the reference. The source and reference text are available at [https://github.com/wmt-conference/wmt24-news-systems](https://github.com/wmt-conference/wmt24-news-systems).

- `documents/SRC-TRG.docs`: For the given `SRC-TRG` language pair, this file contains tab-separated data, where the first column is the domain and the second is the document name. Our data only consists of the `news` domain data from the WMT test sets. These document IDs can be used to match the system outputs to source and reference data (available at [https://github.com/wmt-conference/wmt24-news-systems](https://github.com/wmt-conference/wmt24-news-systems)).
    - Per-line contents: DOMAIN DOCUMENT
    - Line order matches WMT source and reference
- `system-outputs/SRC-TRG/SYSNAME.txt`: For the given `SRC-TRG` language pair and an MT system (`SYSNAME`), this file contains the MT system's output (over the same set of lines in the same order as listed in the `documents/SRC-TRG.docs`) file. These translations were produced by the MT systems trained for this paper.
    - Per-line contents: Translation
    - Line order matches `documents/SRC-TRG.docs`
- `metric-scores/SRC-TRG/METRICNAME-REF.seg.score`: For the given `SRC-TRG` language pair, metric `METRICNAME`, and the reference set `REF` (either `refA` or, in the case of referenceless metrics, `src`) used by the metric, these files contain tab-separated data. The three columns are `DOMAIN` (always `news`), `SYSNAME` (the name of the MT system), and `SCORE` (the segment-level score). These metric scores were generated by participants in the Metrics shared task. Note that the system we submitted to the General MT task received two sets of scores; here we reproduce the scores that were assigned to this output as part of the MSLC challenge set submission, not as it was scored as a General MT task submission (the system output is identical in the two cases, but for some metrics the assigned scores differ; see the [paper](https://aclanthology.org/2024.wmt-1.34/) for more discussion).
    - Per-line contents: DOMAIN SYSNAME SCORE
    - For each SYSNAME, the line order matches `documents/SRC-TRG.docs`
- `mapping/SRC-TRG.tsv`: For the language pair, this maps the MT system name from the number assigned to it in the challenge set to the letter name used in the [paper](https://aclanthology.org/2024.wmt-1.34/). See the paper's appendix for the mapping between the letter and the checkpoint.
    - Per-line contents: SYSNAME LETTER

### MSLC-B
Within the `MSLC-B/` directory, you will find a subdirectory for each language pair: `en-de/`, `en-es/` and `ja-zh/`. Each contains the following:
- `metrics-scores/METRICNAME-REF.seg.score`: For the given metric `METRICNAME` (which was computed using as `REF` either the supplied reference, `ref`, or, in the case of referenceless metrics, the supplied source, `src`) this contains one score per line in the same order as `source.txt` (described below). These scores were generated by participants in the Metrics shared task.
- `source.txt`: The source text, one segment per line.
- `reference.txt`: The reference text, one segment per line, same order as `source.txt`.
- `hypothesis.txt`: The hypothesis text, one segment per line, same order as `source.txt`.
- `types.tsv`: Information about the phenomena covered in the MSLC-B challenge set; tab-separated, same order as `source.txt`.
    - Per-line (tab-separated) contents: SEGID GENERAL SOURCE REFERENCE HYPOTHESIS
    - SEGID is the segment ID as presented in the challenge set data
    - GENERAL describes the phenomena being targeted by the given entry and consists of one of the following (not all categories are included for all language pairs):
      - `empty-hypothesis`: empty hypothesis (simulating an MT system generating the empty string)
      - `empty-source-and-reference`: non-empty hypothesis with empty source and reference (simulating an MT system overgenerating fluent text from no input)
      - `untranslated`: hypothesis matches the source (source left untranslated)
      - `wrong-language`: a valid and fluent hypothesis in a language other than the intended target (for `en-es` and `en-de`, the reference for one language is used as the hypothesis for the other; for `ja-zh` the wrong language is English)
      - `mix-language`: a hypothesis with full coverage of the source, but in a mix of languages (for `en-de` and `en-es` this is a mix of the German `refB` and the Spanish reference; for `ja-zh` this is a mix of Chinese and English)
      - `correct-language`: a hypothesis in the correct language but not identical to the reference (only available for `en-de`, using `refB`)
      - `language-variants`: examples for examining how metrics perform on language variants (only available in `en-es`)
    - SOURCE describes the type of source data in this entry:
      - `empty`: empty string
      - `s-punct`: punctuation mark
      - `s-word`: source language word
      - `s-phrase`: source language phrase
      - `s-sent`: source language sentence or paragraph; these are drawn from the WMT data
      - `English`: for `language-variants` data, this indicates that the source is English
    - REFERENCE describes the type of reference data in this entry:
      - `empty`: empty string
      - `r-punct`: punctuation mark
      - `r-word`: target language word
      - `r-phrase`: target language phrase
      - `r-sent`: target language sentence or paragraph drawn from WMT data
      - `LA` or `Spain`: for the `language-variants` category this indicates whether the term is commonly used in Spain or Latin America (LA)
    - HYPOTHESIS describes the type of hypothesis data in this entry:
      - `empty`: empty string
      - `punct`: punctuation mark
      - `s-{word,phrase,sent}`: source language word, phrase, or sentence/paragraph
      - `r-{word,phrase,sent}`: target language/reference word, phrase or sentence/paragraph
      - `wl-{word,phrase,sent}`: wrong-language (Spanish/German for `en-de` and `en-es`, respectively; English for `ja-zh`)
      - `mix-sent`: mixed-language sentence (for `en-de` and `en-es` this is a mix of the German `refB` and the Spanish reference; for `ja-zh` this is a mix of Chinese and English)
      - `refB`: the `refB` text from the `en-de` WMT dataset
      - `LA` or `Spain`: for the `language-variants` category this indicates whether the term is commonly used in Spain or Latin America (LA)

## Figures
For interactive figures, see: [https://nrc-cnrc.github.io/MSLC/2024/interactive/charts.html](https://nrc-cnrc.github.io/MSLC/2024/interactive/charts.html)

Others to be uploaded shortly.

## Licence
The contents of this repository are released under a [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/) licence.

## Citing this work
If you choose to use this data, please cite:

```bibtex
@inproceedings{knowles-etal-2024-mslc24,
  title = "{MSLC}24: Further Challenges for Metrics on a Wide Landscape of Translation Quality",
  author = "Knowles, Rebecca  and
      Larkin, Samuel  and
      Lo, Chi-kiu",
  editor = "Haddow, Barry  and
      Kocmi, Tom  and
      Koehn, Philipp  and
      Monz, Christof",
  booktitle = "Proceedings of the Ninth Conference on Machine Translation",
  month = nov,
  year = "2024",
  address = "Miami, Florida, USA",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.wmt-1.34",
  pages = "475--491",
}
```
